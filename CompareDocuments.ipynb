{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize #make sure to install the corpus\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "'''\n",
    "Compares `file1` and `file2` for similarity. Set the `threshold`\n",
    "value to the level of similarity you want to detect (0.5 is a good start).\n",
    "Then set the `maxLen` variable to around 30 to avoid very short sentences.\n",
    "This verision supports txt and docx files, use the corresponding two \n",
    "functions, or write your own ones for other file formats. \n",
    "Note: This algorithm is not very efficient on large files.\n",
    "\n",
    "Author: christopher.kullenberg@gmail.com\n",
    "'''\n",
    "\n",
    "# Settings:\n",
    "threshold = 0.5\n",
    "maxLen = 30\n",
    "file1 = 'path/filename'\n",
    "file2 = 'path/filename2'\n",
    "\n",
    "def txtParser(fn):\n",
    "    '''Input: txt-file\n",
    "    Output: text as string'''\n",
    "    try:\n",
    "        thefile = open(fn, 'r', encoding=\"utf-8\")\n",
    "        thetext = thefile.read()\n",
    "    except UnicodeError:\n",
    "        print(\"Unicode error. Save as Unicode / UTF-8.\")\n",
    "    return(thetext)\n",
    "\n",
    "def docxParser(fn):\n",
    "    from docx import Document\n",
    "    '''Input: docx-file\n",
    "    Output: text as string\n",
    "    Note: Build docx from source \n",
    "    https://github.com/python-openxml/python-docx'''\n",
    "    text = \"\"\n",
    "    documenttext = Document(fn)\n",
    "    for d in documenttext.paragraphs:\n",
    "        text += d.text\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compareSent(document1, document2, threshold, maxLen):\n",
    "    '''\n",
    "    Input: Two texts as strings, threshold value as float, maxLen as int.  \n",
    "    Output: Prints sentences that are more similar than the threshold value for m.ratio().\n",
    "    Filter: Excludes sentences shorter than maxLen chars. (Recommended: 30)\n",
    "    '''\n",
    "    sentences1 = sent_tokenize(document1)\n",
    "    sentences2 = sent_tokenize(document2)\n",
    "    for s in sentences1:\n",
    "        if len(s) > maxLen: \n",
    "            for x in sentences2:\n",
    "                if len(x) > maxLen:\n",
    "                    m = SequenceMatcher(None, s, x)\n",
    "                    if m.ratio() > threshold:\n",
    "                        print(\"*\" * 10)\n",
    "                        print(\"Similarity ratio: \" + str(round(m.ratio(), 2)))\n",
    "                        print(\"\\nSentence in File1:\\n\\n\\t\" + s)\n",
    "                        print(\"\\nSentence in File2:\\n\\n\\t\" + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compareSent(txtParser(file1), txtParser(file2), threshold, maxLen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
